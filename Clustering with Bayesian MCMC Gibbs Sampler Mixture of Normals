#Clustering with Bayesian MCMC Gibbs Sampler Mixture of Normals 


#########Fake Data for testing##################
#n = 500
#true.mu = c(2,5)
#true.sigma = c(.8,.5)
#w.true = c(.3,.7)
#sample
#cc.true = sample(c(1,2),size = n, replace = T, prob = w.true)
#x = vector(length = n)
#for(i in 1:n) {
#  x[i] = rnorm(1,true.mu[cc.true[i]],true.sigma[cc.true[i]])
#}
#xx = seq(-1,7,by = .1)
#density.true = w.true[1]*dnorm(xx,true.mu[1],true.sigma[1]) + w.true[2]*dnorm(xx,true.mu[2],true.sigma[2])
#plot(xx,density.true, type = 'l', col = 'blue')

###############################################

data(faithful)
KK = 2          # Based on the description of the dataset
x  = faithful$eruptions
n = length(x)

## Set priors via empirical bayesian approach
aa  = rep(1,KK)  
eta = mean(x)    
tau = sd(x)
dd  = 2
qq  = var(x)/KK

## Initialize the parameters
w = rep(1,KK)/KK    #Weights
mu = rnorm(KK, mean(x), sd(x))   #Means randomly around mean of dataset
sigma = rep(1,KK)*sd(x)/KK #SD set to be the same to start
cc = sample(1:KK, n, replace=T, prob=w) #Indexes generated randomly

## Number of iterations of the sampler
rrr   = 12000
burn  = 2000

## Storing the samples
cc.out    = array(0, dim=c(rrr, n))
w.out     = array(0, dim=c(rrr, KK))
mu.out    = array(0, dim=c(rrr, KK))
sigma.out = array(0, dim=c(rrr, KK))
logpost   = rep(0, rrr)


for(s in 1:rrr){
  # Sample the indicators
  for(i in 1:n){
    v = rep(0,KK)
    for(k in 1:KK){
      v[k] = log(w[k]) + dnorm(x[i], mu[k], sigma[k], log=TRUE)  #Compute the log of the weights
    }
    v = exp(v - max(v))/sum(exp(v - max(v)))
    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)
  }
  
  # Sample the weights
  w = as.vector(rdirichlet(1, aa + tabulate(cc, nbins=KK)))
  
  # Sample the means
  for(k in 1:KK){
    nk    = sum(cc==k)
    xsumk = sum(x[cc==k])
    tau2.hat = 1/(nk/sigma[k]^2 + 1/tau^2)
    mu.hat  = tau2.hat*(xsumk/sigma[k]^2 + eta/tau^2)
    mu[k]   = rnorm(1, mu.hat, sqrt(tau2.hat))
  }
  
  # Sample the variances
  for(k in 1:KK) {
    nk = sum(cc==k)
    dd.star = dd + nk/2
    qq.star = qq + sum((x[cc==k] - mu[k])^2)/2
    sigma[k] = sqrt(1/rgamma(1, dd.star, qq.star))
  }
  # Store samples
  cc.out[s,]   = cc
  w.out[s,]    = w
  mu.out[s,]   = mu
  sigma.out[s,] = sigma
}

#Calculate samples of density over a grid for easy plotting
xx = seq(0,7,by=.1)
density.mcmc = array(0, dim=c(rrr-burn,length(xx)))
for(s in 1:(rrr-burn)){
  for(k in 1:KK){
    density.mcmc[s,] = density.mcmc[s,] + w.out[s+burn,k]*dnorm(xx,mu.out[s+burn,k],sigma.out[s+burn,k])
  }
}
density.mcmc.m = apply(density.mcmc , 2, mean)

## Plot Bayesian estimate with pointwise credible bands along with kernel density estimate
colscale = c("black", "red")

yy = density(x)
density.mcmc.lq = apply(density.mcmc, 2, quantile, 0.025)
density.mcmc.uq = apply(density.mcmc, 2, quantile, 0.975)
plot(xx, density.mcmc.m, type="n",ylim=c(0,max(density.mcmc.uq)),ylab="Density")
polygon(c(xx,rev(xx)), c(density.mcmc.lq, rev(density.mcmc.uq)), col="grey", border="grey")
lines(xx, density.mcmc.m, col=colscale[1], lwd=2)
lines(yy, col=colscale[2], lty=2, lwd=2)
points(x, rep(0,n))
legend('topright', c("KDE","MCMC"), col=colscale[c(2,1)], lty=c(2,1), lwd=2, bty="n")
